{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we show how to perform the forward pass through the Neural ODE using different types of Meta Solver regimes, namely\n",
    "- Standalone\n",
    "- Solver switching/smoothing\n",
    "- Solver ensembling\n",
    "- Model ensembling\n",
    "\n",
    "In more details, usage of different regimes means\n",
    "- **Standalone**\n",
    "    - Use one solver during  inference\n",
    "    - Applied during training/testing.\n",
    "     \n",
    "    \n",
    "    \n",
    "- **Solver switching / smoothing**\n",
    "    - For each batch one solver is chosen from a group of solvers with finite (in switching regime) or infinite (in smoothing regime) number of members.\n",
    "    - Applied during training.\n",
    "    \n",
    "    \n",
    "- **Solver ensembling**\n",
    "    - Use several solvers durung inference.\n",
    "    - Outputs of ODE Block (obtained with different solvers) are averaged before propagating through the next layer.\n",
    "    - Applied during training/testing\n",
    "    \n",
    "    \n",
    "- **Model ensembling**\n",
    "    - Use several solvers durung inference.\n",
    "    - Model probabilites obtained via propagation with different solvers are averaged to get the final result.\n",
    "    - Applied during training/testing\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER']=\"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICE']=\"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "import torch\n",
    "import numpy as np\n",
    "import itertools\n",
    "import wandb\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('../../')\n",
    "import sopa.src.models.odenet_cifar10.layers as cifar10_models\n",
    "from sopa.src.models.odenet_cifar10.utils import *\n",
    "from sopa.src.models.odenet_cifar10.data import get_cifar10_test_loader\n",
    "from sopa.src.models.utils import fix_seeds\n",
    "from sopa.src.solvers.utils import create_solver, noise_params, create_solver_ensemble_by_noising_params\n",
    "\n",
    "from MegaAdversarial.src.attacks import (\n",
    "    Clean,\n",
    "    PGD,\n",
    "    FGSM,\n",
    "    Clean2Ensemble,\n",
    "    FGSM2Ensemble,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a checkpoint\n",
    "\n",
    "# checkpoint_name = './checkpoints/fgsm_random_8_255.pth'\n",
    "checkpoint_name = './checkpoints/fgsm_random_8_255_smoothing_00125.pth'\n",
    "\n",
    "checkpoint=torch.load(checkpoint_name)\n",
    "config = Namespace(**checkpoint['wandb_config'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['rk2', 'u', 8, -1.0, 0.5, -1]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solvers used during model training\n",
    "config.solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Neural ODE model\n",
    "norm_layers = (get_normalization(config.normalization_resblock),\n",
    "               get_normalization(config.normalization_odeblock),\n",
    "               get_normalization(config.normalization_bn1))\n",
    "param_norm_layers = (get_param_normalization(config.param_normalization_resblock),\n",
    "                     get_param_normalization(config.param_normalization_odeblock),\n",
    "                     get_param_normalization(config.param_normalization_bn1))\n",
    "act_layers = (get_activation(config.activation_resblock),\n",
    "              get_activation(config.activation_odeblock),\n",
    "              get_activation(config.activation_bn1))\n",
    "\n",
    "model = getattr(cifar10_models, config.network)(norm_layers, param_norm_layers, act_layers,\n",
    "                                                config.in_planes, is_odenet=config.is_odenet)\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "\n",
    "checkpoint=None\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_root=\"/workspace/raid/data/datasets/cifar10\"\n",
    "test_loader = get_cifar10_test_loader(batch_size=32,\n",
    "                                      data_root=data_root,\n",
    "                                      num_workers=1,\n",
    "                                      pin_memory=False,\n",
    "                                      shuffle=False,\n",
    "                                      download=False)\n",
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(x, K):\n",
    "    return np.array(x[:, None] == np.arange(K)[None, :], dtype=int)\n",
    "\n",
    "def accuracy(model, dataset_loader, device, solvers=None, solver_options=None, data_noise_std=None):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    total_correct = 0\n",
    "\n",
    "    for x, y in dataset_loader:\n",
    "        x = x.to(device)\n",
    "        y = one_hot(np.array(y.numpy()), 10)\n",
    "        target_class = np.argmax(y, axis=1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Add noise:\n",
    "            if (data_noise_std is not None) and (data_noise_std > 1e-12):\n",
    "                x = x + data_noise_std * torch.randn_like(x)\n",
    "                \n",
    "            if solvers is not None:\n",
    "                out = model(x, solvers, solver_options).cpu().detach().numpy()\n",
    "            else:\n",
    "                out = model(x).cpu().detach().numpy()\n",
    "            predicted_class = np.argmax(out, axis=1)\n",
    "            total_correct += np.sum(predicted_class == target_class)\n",
    "\n",
    "    total = len(dataset_loader) * dataset_loader.batch_size\n",
    "    torch.cuda.empty_cache()\n",
    "    return total_correct / total\n",
    "\n",
    "def adversarial_accuracy(model, dataset_loader, device, solvers=None, solver_options=None, args=None):\n",
    "    global CONFIG_PGD_TEST\n",
    "    global CONFIG_FGSM_TEST\n",
    "    \n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    total_correct = 0\n",
    "\n",
    "    if args.a_adv_testing_mode == \"clean\":\n",
    "        test_attack = Clean(model)\n",
    "    elif args.a_adv_testing_mode == \"fgsm\":\n",
    "        test_attack = FGSM(model, **CONFIG_FGSM_TEST)\n",
    "    elif args.a_adv_testing_mode == \"at\":\n",
    "        test_attack = PGD(model, **CONFIG_PGD_TEST)\n",
    "    else:\n",
    "        raise ValueError(\"Attack type not understood.\")\n",
    "    for x, y in dataset_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        x, y = test_attack(x, y, {\"solvers\": solvers, \"solver_options\": solver_options})\n",
    "        y = one_hot(np.array(y.cpu().numpy()), 10)\n",
    "        target_class = np.argmax(y, axis=1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            if solvers is not None:\n",
    "                out = model(x, solvers, solver_options).cpu().detach().numpy()\n",
    "            else:\n",
    "                out = model(x).cpu().detach().numpy()\n",
    "            predicted_class = np.argmax(out, axis=1)\n",
    "            total_correct += np.sum(predicted_class == target_class)\n",
    "\n",
    "    total = len(dataset_loader) * dataset_loader.batch_size\n",
    "    torch.cuda.empty_cache()\n",
    "    return total_correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_mean, cifar10_std = (0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "CONFIG_FGSM_TEST = {\"eps\": 8/255., \"mean\": cifar10_mean, \"std\": cifar10_std}\n",
    "CONFIG_PGD_TEST = {\"eps\": 8/255., \"lr\": 2/255., \"n_iter\": 7,\n",
    "                   \"mean\": cifar10_mean, \"std\": cifar10_std}\n",
    "\n",
    "device='cuda'\n",
    "dtype=torch.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standalone\n",
    "- Use one solver during  inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a solver\n",
    "val_solvers = [create_solver(method='rk2',\n",
    "                             parameterization='u',\n",
    "                             n_steps=8,\n",
    "                             step_size=-1,\n",
    "                             u0=0.5,\n",
    "                             v0=-1,\n",
    "                             dtype=dtype,\n",
    "                             device=device)]\n",
    "# Freeze solver params\n",
    "for solver in val_solvers:\n",
    "    solver.freeze_params()\n",
    "\n",
    "val_solver_options = Namespace(**{'solver_mode': 'standalone'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8279246794871795"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute standard accuracy\n",
    "accuracy_test = accuracy(model, test_loader, device=device,\n",
    "                         solvers=val_solvers, solver_options=val_solver_options)\n",
    "accuracy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41616586538461536"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute robust accuracy\n",
    "# a_adv_testing_mode = 'fgsm' for FGSM, or 'at' for PGD\n",
    "a_adv_testing_mode = 'fgsm' \n",
    "adv_accuracy_test = adversarial_accuracy(model, test_loader, device,\n",
    "                                         solvers=val_solvers, solver_options=val_solver_options,\n",
    "                                         args = Namespace(**{'a_adv_testing_mode': 'fgsm'}))\n",
    "adv_accuracy_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solver switching\n",
    "For each batch one solver is chosen from a group of solvers with finite (in switching regime) or infinite (in smoothing regime) number of members."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda'\n",
    "dtype=torch.float32\n",
    "val_solvers = [create_solver(method='rk2', parameterization='u', n_steps=8, step_size=-1, u0=0.5, v0=-1,\n",
    "                             dtype=dtype, device=device),\n",
    "              create_solver(method='rk2', parameterization='u', n_steps=8, step_size=-1, u0=1., v0=-1,\n",
    "                             dtype=dtype, device=device)]\n",
    "for solver in val_solvers:\n",
    "    solver.freeze_params()\n",
    "    \n",
    "val_solver_options = Namespace(**{'solver_mode': 'switch', 'switch_probs': [0.6, 0.4]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8277243589743589"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_test = accuracy(model, test_loader, device=device,\n",
    "                         solvers=val_solvers, solver_options=val_solver_options)\n",
    "accuracy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41616586538461536"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_accuracy_test = adversarial_accuracy(model, test_loader, device,\n",
    "                                         solvers=val_solvers, solver_options=val_solver_options,\n",
    "                                         args = Namespace(**{'a_adv_testing_mode': 'fgsm'})\n",
    "                                        )\n",
    "adv_accuracy_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solver Ensembling\n",
    "- Use several solvers durung inference.\n",
    "\n",
    "- Outputs of ODE Block (obtained with different solvers) are averaged before propagating through the next layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_solvers = [create_solver(method='rk2', parameterization='u', n_steps=8, step_size=-1, u0=0.5, v0=-1,\n",
    "                             dtype=dtype, device=device),\n",
    "              create_solver(method='rk2', parameterization='u', n_steps=8, step_size=-1, u0=1., v0=-1,\n",
    "                             dtype=dtype, device=device)]\n",
    "for solver in val_solvers:\n",
    "    solver.freeze_params()\n",
    "    \n",
    "val_solver_options = Namespace(**{'solver_mode': 'ensemble',\n",
    "                                  'ensemble_prob':1, 'ensemble_weights': [0.6, 0.4]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8278245192307693"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_test = accuracy(model, test_loader, device=device,\n",
    "                         solvers=val_solvers, solver_options=val_solver_options)\n",
    "accuracy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41626602564102566"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_accuracy_test = adversarial_accuracy(model, test_loader, device,\n",
    "                                         solvers=val_solvers, solver_options=val_solver_options,\n",
    "                                         args = Namespace(**{'a_adv_testing_mode': 'fgsm'})\n",
    "                                        )\n",
    "adv_accuracy_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Ensembling\n",
    "- Use several solvers durung inference.\n",
    "\n",
    "- Model probabilites obtained via propagation with different solvers are averaged to get the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_ensemble(models, dataset_loader, device, solvers_solver_options_arr=None, data_noise_std=None):\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "    total_correct = 0\n",
    "\n",
    "    for x, y in dataset_loader:\n",
    "        x = x.to(device)\n",
    "        y = one_hot(np.array(y.numpy()), 10)\n",
    "        target_class = np.argmax(y, axis=1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Add noise:\n",
    "            if (data_noise_std is not None) and (data_noise_std > 1e-12):\n",
    "                x = x + data_noise_std * torch.randn_like(x)\n",
    "\n",
    "            probs_ensemble = 0\n",
    "\n",
    "            if solvers_solver_options_arr is not None:\n",
    "                for n, (model, solvers_solver_options) in enumerate(\n",
    "                        itertools.zip_longest(models, solvers_solver_options_arr, fillvalue=models[0])):\n",
    "                    logits = model(x, **solvers_solver_options)\n",
    "                    probs = nn.Softmax(dim=1)(logits).cpu().detach().numpy()\n",
    "                    probs_ensemble = probs_ensemble + probs\n",
    "\n",
    "            else:\n",
    "                for n, model in enumerate(models):\n",
    "                    logits = model(x)\n",
    "                    probs = nn.Softmax()(logits).cpu().detach().numpy()\n",
    "                    probs_ensemble = probs_ensemble + probs\n",
    "\n",
    "            probs_ensemble /= (n + 1)\n",
    "\n",
    "            predicted_class = np.argmax(probs_ensemble, axis=1)\n",
    "            total_correct += np.sum(predicted_class == target_class)\n",
    "\n",
    "    total = len(dataset_loader) * dataset_loader.batch_size\n",
    "    return total_correct / total\n",
    "\n",
    "\n",
    "def adversarial_accuracy_ensemble(models, dataset_loader, device, solvers_solver_options_arr=None, args=None):\n",
    "    global CONFIG_PGD_TEST\n",
    "    global CONFIG_FGSM_TEST\n",
    "\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "    total_correct = 0\n",
    "\n",
    "    if args.a_adv_testing_mode == \"clean\":\n",
    "        test_attack = Clean2Ensemble(models)\n",
    "    elif args.a_adv_testing_mode == \"fgsm\":\n",
    "        test_attack = FGSM2Ensemble(models, **CONFIG_FGSM_TEST)\n",
    "    else:\n",
    "        raise ValueError(\"Attack type is not implemented for ensemble of models\")\n",
    "\n",
    "    for x, y in dataset_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        x, y = test_attack(x, y, solvers_solver_options_arr)\n",
    "        y = one_hot(np.array(y.cpu().numpy()), 10)\n",
    "        target_class = np.argmax(y, axis=1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            probs_ensemble = 0\n",
    "\n",
    "            if solvers_solver_options_arr is not None:\n",
    "                for n, (model, solvers_solver_options) in enumerate(\n",
    "                        itertools.zip_longest(models, solvers_solver_options_arr, fillvalue=models[0])):\n",
    "                    logits = model(x, **solvers_solver_options)\n",
    "                    probs = nn.Softmax(dim=1)(logits).cpu().detach().numpy()\n",
    "                    probs_ensemble = probs_ensemble + probs\n",
    "\n",
    "            else:\n",
    "                for n, model in enumerate(models):\n",
    "                    logits = model(x)\n",
    "                    probs = nn.Softmax()(logits).cpu().detach().numpy()\n",
    "                    probs_ensemble = probs_ensemble + probs\n",
    "\n",
    "            probs_ensemble /= (n + 1)\n",
    "\n",
    "            predicted_class = np.argmax(probs_ensemble, axis=1)\n",
    "            total_correct += np.sum(predicted_class == target_class)\n",
    "\n",
    "    total = len(dataset_loader) * dataset_loader.batch_size\n",
    "    return total_correct /total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7345], device='cuda:0') None\n"
     ]
    }
   ],
   "source": [
    "val_solvers = [create_solver(method='rk2',\n",
    "                             parameterization='u',\n",
    "                             n_steps=8,\n",
    "                             step_size=-1,\n",
    "                             u0=0.5,\n",
    "                             v0=-1,\n",
    "                             dtype=dtype,\n",
    "                             device=device)]\n",
    "for solver in val_solvers:\n",
    "    solver.freeze_params()\n",
    "\n",
    "val_solver_options = Namespace(**{'solver_mode': 'standalone'})\n",
    "\n",
    "ensemble_size = 2\n",
    "solver_ensemble = create_solver_ensemble_by_noising_params(val_solvers[0],\n",
    "                                                           ensemble_size=ensemble_size,\n",
    "                                                           kwargs_noise={'std': 0.2,\n",
    "                                                                         'bernoulli_p': 1.,\n",
    "                                                                         'noise_type': 'normal'})\n",
    "\n",
    "solvers_solver_options_arr = [{'solvers': [solver], 'solver_options': val_solver_options}\n",
    "                              for solver in solver_ensemble]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8279246794871795"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_test = accuracy_ensemble([model], test_loader, device=device,\n",
    "                                  solvers_solver_options_arr=solvers_solver_options_arr,)\n",
    "accuracy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../../MegaAdversarial/src/attacks/fgsm.py:139: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs_ensemble = probs_ensemble + nn.Softmax()(logits)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.41626602564102566"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_accuracy_test = adversarial_accuracy_ensemble([model], test_loader, device=device,\n",
    "                                                  solvers_solver_options_arr=solvers_solver_options_arr,\n",
    "                                                  args=Namespace(**{'a_adv_testing_mode': 'fgsm'}))\n",
    "adv_accuracy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
